{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrWT2dYcVaZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a022a5b-03f3-47e8-82a9-1b327c5484c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = './drive/MyDrive/ml_class_group_project/Vijay/bert-fine-tuned-ner/checkpoint-5268'"
      ],
      "metadata": {
        "id": "D0fpHpHOM2PH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n"
      ],
      "metadata": {
        "id": "7Ru-nYmxNLsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_dir)"
      ],
      "metadata": {
        "id": "xaT0WvJ7Nkga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def predict(text:str):\n",
        "\n",
        "  inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "  ids_list = inputs['input_ids']\n",
        "  tokens = inputs.tokens()\n",
        "\n",
        "  # print(type(ids_list[0][3].item()))\n",
        "  # print(IntTensor.item(ids_list[0][3]))\n",
        "  # print(inputs.tokens())\n",
        "\n",
        "  # for id in tf.unstack(ids_list):\n",
        "\n",
        "  #   print(id)\n",
        "\n",
        "  # print()\n",
        "\n",
        "\n",
        "  # print(inputs.input_ids())\n",
        "  # inputs.decode()\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    logits = model(**inputs).logits\n",
        "\n",
        "\n",
        "    predictions = torch.argmax(logits, dim=2)\n",
        "\n",
        "\n",
        "    predicted_token_class = [model.config.id2label[t.item()] for t in predictions[0]]\n",
        "\n",
        "  # return (tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=True), predicted_token_class)\n",
        "  # return (text, skip_special_tokens=True), predicted_token_class)\n",
        "\n",
        "  # return (text, predicted_token_class)\n",
        "\n",
        "  return (tokens, ids_list, predicted_token_class)"
      ],
      "metadata": {
        "id": "Cjtki3tNN2ZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_subtokens_and_update_labels_list(result_from_predict_function):\n",
        "\n",
        "  tokens_list = result_from_predict_function[0]\n",
        "  ids_list = result_from_predict_function[1].tolist()[0]\n",
        "  labels_list = result_from_predict_function[2]\n",
        "\n",
        "  # print(type(tokens_list))\n",
        "  # print(type(ids_list))\n",
        "  # print(type(labels_list))\n",
        "\n",
        "  # print(tokens_list)\n",
        "  # print(ids_list)\n",
        "  # print(labels_list)\n",
        "\n",
        "  length_of_labels_list = len(labels_list)\n",
        "\n",
        "  index = 0\n",
        "\n",
        "  all = []\n",
        "\n",
        "  while index < length_of_labels_list:\n",
        "\n",
        "    current_index = index\n",
        "    group = []\n",
        "\n",
        "    while current_index < length_of_labels_list and 'ORG' in labels_list[current_index]:\n",
        "\n",
        "      group.append(ids_list[current_index])\n",
        "      current_index += 1\n",
        "\n",
        "\n",
        "    if len(group) > 0:\n",
        "\n",
        "      all.append(tokenizer.decode(group))\n",
        "\n",
        "    if current_index == index:\n",
        "\n",
        "      index += 1\n",
        "\n",
        "    else:\n",
        "\n",
        "      index = current_index\n",
        "\n",
        "\n",
        "  return all\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iHTS89wsr4sZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict('The Golden State Warriors are an American professional basketball team based in San Francisco.')\n",
        "# predict('Microsoft is a company')\n",
        "\n",
        "# result_from_predict_function = predict('Desectorization is a company')\n",
        "\n",
        "# merge_subtokens_and_update_labels_list(result_from_predict_function)\n",
        "\n",
        "print(merge_subtokens_and_update_labels_list(predict('Hewlett Packard Enterprise is a company.')))\n",
        "\n",
        "print(merge_subtokens_and_update_labels_list(predict('Mukesh Ambani is the chairman of Reliance Industries Limited')))\n",
        "\n",
        "print(merge_subtokens_and_update_labels_list(predict('Mukesh Ambani is the chairman of Reliance Industries Limited')))\n",
        "\n",
        "merge_subtokens_and_update_labels_list(predict('Amazon and Tesla are currently the best picks out there'))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIT14JdkYVOz",
        "outputId": "a2e7705a-3aa6-4d26-80a3-c0a0811d995d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hewlett Packard Enterprise']\n",
            "['Reliance Industries Limited']\n",
            "['Reliance Industries Limited']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Amazon', 'Tesla']"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to handle any type of entity\n",
        "\n",
        "def get_entities(text, entity):\n",
        "\n",
        "  # text = re.sub(pattern='[^\\w\\s]', repl='', string=text)\n",
        "  # print(text)\n",
        "  # print(entity)\n",
        "\n",
        "  labels_list = predict(text)[1]\n",
        "\n",
        "  tokens_list = text.split()\n",
        "  entities_list = list()\n",
        "\n",
        "  # print(labels_list)\n",
        "  # print(tokens_list)\n",
        "  # print(len(labels_list) == len(tokens_list))\n",
        "\n",
        "  pairings_list = tuple(zip(tokens_list, labels_list))\n",
        "  # print(pairings_list)\n",
        "\n",
        "  index = 0\n",
        "  length_of_pairings_list = len(pairings_list)\n",
        "\n",
        "  while index < length_of_pairings_list:\n",
        "\n",
        "    current_index = index\n",
        "    new_entity_name = ''\n",
        "\n",
        "    while current_index < length_of_pairings_list and entity in pairings_list[current_index][1]:\n",
        "\n",
        "      new_entity_name += pairings_list[current_index - 1][0] + ' '\n",
        "      current_index += 1\n",
        "\n",
        "    if len(new_entity_name) > 0:\n",
        "\n",
        "      new_entity_name = new_entity_name.strip()\n",
        "\n",
        "      entities_list.append(new_entity_name)\n",
        "\n",
        "    index += 1 if index == current_index else current_index\n",
        "\n",
        "  return entities_list if len(entities_list) > 0 else 'No entities found'\n"
      ],
      "metadata": {
        "id": "pfvWcyuMjCIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Single Word Organization Tests\n",
        "\n",
        "entities = get_entities('Microsoft and Google are large tech companies', 'ORG')\n",
        "print(entities)\n",
        "\n",
        "entities = get_entities('Apple and Amazon are competing with each other', 'ORG')\n",
        "print(entities)\n",
        "\n",
        "entities = get_entities('Spring has sprung at Amazon', 'ORG')\n",
        "print(entities)\n",
        "\n",
        "entities = get_entities('George is a student at university', 'PER')\n",
        "print(entities)\n",
        "\n",
        "entities = get_entities('Johnny delivers pizza in New York.', 'PER')\n",
        "print(entities)\n",
        "\n",
        "entities = get_entities('German is a language spoken in Germany', 'MISC')\n",
        "print(entities)\n",
        "\n",
        "# The below example doesn't work due to subword tokenization\n",
        "\n",
        "entities = get_entities('Hewlett Packard Enterprise is a company.', 'ORG')\n",
        "print(entities)\n",
        "\n",
        "\n",
        "entities = get_entities('Mukesh Ambani is the chairman of Reliance Industries Limited', 'ORG')\n",
        "\n",
        "entities = get_entities('amazon and tesla are currently the best picks out there', 'ORG')\n",
        "\n",
        "# Multiple Word Organization Tests\n",
        "\n",
        "entities = get_entities('British Airways is better than American Airlines.', 'ORG')\n",
        "print(entities)\n",
        "\n",
        "entities = get_entities('The United Nations and the World Bank are well known organizations.', 'ORG')\n",
        "print(entities)\n",
        "\n",
        "entities = get_entities('The World Trade Organization is an intergovernmental organization headquartered in Geneva, Switzerland.', 'ORG')\n",
        "print(entities)\n",
        "\n",
        "entities = get_entities('Johnny delivers pizza in New York.', 'LOC')\n",
        "print(entities)\n"
      ],
      "metadata": {
        "id": "qGdizXvHjVpe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59e61fcb-7d7a-4bda-e6e5-6960cac6295c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Microsoft', 'Google']\n",
            "['Apple', 'Amazon']\n",
            "No entities found\n",
            "['George']\n",
            "['Johnny']\n",
            "['German']\n",
            "['Hewlett Packard Enterprise is a']\n",
            "['British Airways', 'American']\n",
            "['United Nations', 'World Bank']\n",
            "['World Trade Organization']\n",
            "['New']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mapping(words, labels):\n",
        "\n",
        "  line1 = \"\"\n",
        "  line2 = \"\"\n",
        "\n",
        "  print(words.split())\n",
        "  print(f'Words length is {len(words.split())}')\n",
        "  print(labels)\n",
        "  print(f'Labels length is {len(labels)}')\n",
        "\n",
        "#   for word, label in zip(words, labels):\n",
        "#       # full_label = label_names[label]\n",
        "#       max_length = max(len(word), len(full_label))\n",
        "#       line1 += word + \" \" * (max_length - len(word) + 1)\n",
        "#       line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
        "\n",
        "# print(line1)\n",
        "# print(line2)"
      ],
      "metadata": {
        "id": "DDbepFzwsujJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import requests\n",
        "# from bs4 import BeautifulSoup\n",
        "\n",
        "# def get_organizations(news_article:str):\n",
        "\n",
        "#   req = requests.get(news_article)\n",
        "#   soup = BeautifulSoup(req.content, parser='html')\n",
        "\n",
        "#   content = soup.get_text()\n",
        "\n",
        "#   tokens = content.split()\n",
        "\n",
        "#   for token in tokens:\n",
        "#     print(token)\n",
        "#     print(predict(token))\n",
        "#     print()\n",
        "\n",
        "#   return tokens\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Original one that just gets the word\n",
        "def get_organizations(text):\n",
        "\n",
        "  # call predict and store result in list\n",
        "  # convert text into tokens using split() and store in list\n",
        "  # iterate through labels list starting from index 1\n",
        "  # if tag is 'B-ORG', then go to index - 1 in tokens list\n",
        "  # Append that word into a set\n",
        "  # return set back to caller\n",
        "\n",
        "  labels_list = predict(text)\n",
        "  # print(labels_list)\n",
        "  tokens_list = text.split()\n",
        "  organizations_list = set()\n",
        "\n",
        "  for i in range(1,len(labels_list)):\n",
        "\n",
        "    if labels_list[i] == 'B-ORG':\n",
        "\n",
        "      organizations_list.add(tokens_list[i-1])\n",
        "\n",
        "\n",
        "  if len(organizations_list) == 0:\n",
        "\n",
        "    organizations_list.add('No organizations found.')\n",
        "\n",
        "\n",
        "  return list(organizations_list)\n"
      ],
      "metadata": {
        "id": "wr7fOXWVPTOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "an-3pVl4ql6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(predict(\"Rich and Vijay are students at Northeastern University.\"))\n",
        "# print(predict(\"Microsoft and Google are large tech companies\"))\n",
        "print(predict(\"British Airways is better than American Airlines.\"))"
      ],
      "metadata": {
        "id": "bS7onKnBPJnI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "256b26cb-ad3d-4527-82a3-52de358a7fc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('British Airways is better than American Airlines.', ['O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_organizations_v2(text):\n",
        "\n",
        "  text = re.sub(pattern='[^\\w\\s]', repl='', string=text)\n",
        "\n",
        "  labels_list = predict(text)\n",
        "  tokens_list = text.split()\n",
        "  organizations_list = set()\n",
        "\n",
        "  # print(labels_list)\n",
        "  # print(tokens_list)\n",
        "\n",
        "  index = 1\n",
        "\n",
        "  # n represents the length of the labels_list\n",
        "  n = len(labels_list)\n",
        "\n",
        "  while index < n - 1:\n",
        "\n",
        "    current_index = index\n",
        "    full_organization_name = ''\n",
        "\n",
        "    while 'ORG' in labels_list[index]:\n",
        "\n",
        "      if full_organization_name != '':\n",
        "\n",
        "        full_organization_name += ' ' + tokens_list[index - 1]\n",
        "\n",
        "      else:\n",
        "\n",
        "        full_organization_name = tokens_list[index - 1]\n",
        "\n",
        "\n",
        "\n",
        "      index += 1\n",
        "\n",
        "\n",
        "    if full_organization_name != '':\n",
        "\n",
        "      organizations_list.add(full_organization_name)\n",
        "\n",
        "    if current_index == index:\n",
        "\n",
        "      index += 1\n",
        "\n",
        "  organizations_list = list(organizations_list)\n",
        "\n",
        "  if len(organizations_list) == 0:\n",
        "\n",
        "    organizations_list.append('No organizations found.')\n",
        "\n",
        "  return organizations_list\n"
      ],
      "metadata": {
        "id": "igWotlsWDNYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_company(tokens, tags):\n",
        "    generated_tokens = []\n",
        "    i = 0\n",
        "    while i < len(tags):\n",
        "        if tags[i] == \"B-COMPANY\":\n",
        "            company_token = [tokens[i]]\n",
        "            for j in range(i + 1, len(tags)):\n",
        "                i += 1\n",
        "                if tags[j] != \"X\":\n",
        "                    break\n",
        "                else:\n",
        "                    company_token.append(tokens[j][2:])\n",
        "            generated_tokens.append(\"\".join(company_token))\n",
        "        else:\n",
        "            generated_tokens.append(tokens[i])\n",
        "            i += 1\n",
        "\n",
        "    return generated_tokens"
      ],
      "metadata": {
        "id": "7GX7EPxkG8ZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenized_text = tokenizer('Desectorization')\n",
        "# print(tokenized_text)\n",
        "\n",
        "# print(tokenizer.decode(14177))\n",
        "# print(tokenizer.decode(20302))\n",
        "# print(tokenizer.decode(2734))\n",
        "# print(tokenizer.decode([14177, 20302, 2734]))\n",
        "\n",
        "# tokenizer.decode(tokenized_text['input_ids'])\n",
        "# predict('Desectorization')\n",
        "\n",
        "tokenized_text = tokenizer(['Desectorization', 'Demarcation'], is_split_into_words=True)\n",
        "print(tokenized_text)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(tokenizer.decode(14177))\n",
        "print(tokenizer.decode(20302))\n",
        "print(tokenizer.decode(2734))\n",
        "\n",
        "print(tokenizer.decode(3177))\n",
        "print(tokenizer.decode(7317))\n",
        "print(tokenizer.decode(14520))\n",
        "\n",
        "# print(tokenizer.decode(16978))\n",
        "# print(tokenizer.decode([14177, 20302, 2734, 16978]))\n"
      ],
      "metadata": {
        "id": "msg0sFNIGb7Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47e60208-8b31-4df5-9c47-127403e5a743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [101, 14177, 20302, 2734, 3177, 7317, 14520, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "Des\n",
            "##ector\n",
            "##ization\n",
            "De\n",
            "##mar\n",
            "##cation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Single Word Organization Tests\n",
        "\n",
        "organizations = get_organizations_v2(\"Microsoft and Google are large tech companies\")\n",
        "print(organizations)\n",
        "\n",
        "organizations = get_organizations_v2(\"Apple and Amazon are competing with each other\")\n",
        "print(organizations)\n",
        "\n",
        "organizations = get_organizations_v2(\"Spring has sprung at Amazon\")\n",
        "print(organizations)\n",
        "\n",
        "# Multiple Word Organization Tests\n",
        "\n",
        "organizations = get_organizations_v2(\"British Airways is better than American Airlines.\")\n",
        "print(organizations)\n",
        "\n",
        "organizations = get_organizations_v2(\"The United Nations and the World Bank are well known organizations.\")\n",
        "print(organizations)\n",
        "\n",
        "organizations = get_organizations_v2(\"The World Trade Organization is an intergovernmental organization headquartered in Geneva, Switzerland.\")\n",
        "print(organizations)\n",
        "\n",
        "\n",
        "# Needs Some Work\n",
        "\n",
        "# organizations = get_organizations_v2(\"Hewlett Packard Enterprise is a company.\")\n",
        "# print(organizations)\n",
        "\n",
        "\n",
        "\n",
        "# organizations = get_organizations_v2(\"Mukesh Ambani is the chairman of Reliance Industries Limited\")\n",
        "# print(organizations)\n",
        "\n",
        "\n",
        "# get_organizations('https://www.forbes.com/sites/zakdoffman/2024/03/21/apple-iphone-15-pro-max-upgrade-vs-samsung-galaxy-s24-ultra-s23/?sh=4bcfef0861d7')\n",
        "# tokens = get_organizations('https://realpython.github.io/fake-jobs/jobs/senior-python-developer-0.html')\n",
        "\n",
        "\n",
        "# del predicted_token_class[0]\n",
        "  # del predicted_token_class[-1]\n",
        "\n",
        "  # add special tokens -> remove special tokens\n",
        "  # tokenizer.decode\n",
        "  # use small text\n",
        "  #\n",
        "\n",
        "  # return tuple(zip(text, predicted_token_class))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lukvO8P8Sd9u",
        "outputId": "ea0c04b4-9559-4251-e851-019c90db3ff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['No organizations found.']\n",
            "['No organizations found.']\n",
            "['No organizations found.']\n",
            "['No organizations found.']\n",
            "['No organizations found.']\n",
            "['No organizations found.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing some code here\n",
        "\n",
        "# tokens:\n",
        "tokens = ['[CLS]', 'am', '##az', '##on', 'and', 'te', '##sla', 'are', 'currently', 'the', 'best', 'picks', 'out', 'there']\n",
        "# tags:\n",
        "tags = ['X', 'B-COMPANY', 'X', 'X', 'O', 'B-COMPANY', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
        "\n",
        "tokens = tokens[1:]\n",
        "tags = tags[1:]\n",
        "\n",
        "print(tokens)\n",
        "print(tags)\n"
      ],
      "metadata": {
        "id": "h92gluCnUStc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a8dfa66-277d-435b-b51a-2d45015dad5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['am', '##az', '##on', 'and', 'te', '##sla', 'are', 'currently', 'the', 'best', 'picks', 'out', 'there']\n",
            "['B-COMPANY', 'X', 'X', 'O', 'B-COMPANY', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#my practice of implementing the merge function\n",
        "\n",
        "def merge_entity(tokens, tags):\n",
        "\n",
        "  pass\n"
      ],
      "metadata": {
        "id": "Y0sqQfboIVXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = merge_company(tokens, tags)\n",
        "tags = [tag for tag in tags if tag != \"X\"]\n",
        "\n",
        "print(tokens)\n",
        "print(tags)"
      ],
      "metadata": {
        "id": "-lu2de8UIACw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62b437ea-e328-43ee-9385-c63032bd761a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['amazon', 'and', 'tesla', 'are', 'currently', 'the', 'best', 'picks', 'out', 'there']\n",
            "['B-COMPANY', 'O', 'B-COMPANY', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tuple(zip(tokens, tags)))"
      ],
      "metadata": {
        "id": "FK3yiCK6ID_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f981fc6-b211-458a-a7d8-ef6fd2e2fdc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(('amazon', 'B-COMPANY'), ('and', 'O'), ('tesla', 'B-COMPANY'), ('are', 'O'), ('currently', 'O'), ('the', 'O'), ('best', 'O'), ('picks', 'O'), ('out', 'O'), ('there', 'O'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "05UbasppjyG7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}